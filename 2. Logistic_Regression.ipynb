{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>high_education_ind</th>\n",
       "      <th>address_change_ind</th>\n",
       "      <th>past_num_of_claims</th>\n",
       "      <th>witness_present_ind</th>\n",
       "      <th>liab_prct</th>\n",
       "      <th>policy_report_filed_ind</th>\n",
       "      <th>fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>safety_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday</th>\n",
       "      <th>accident_site_Highway</th>\n",
       "      <th>accident_site_Local</th>\n",
       "      <th>accident_site_Parking Lot</th>\n",
       "      <th>channel_Broker</th>\n",
       "      <th>channel_Online</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>claim_est_payout_category</th>\n",
       "      <th>age_of_vehicle_category</th>\n",
       "      <th>vehicle_price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  high_education_ind  address_change_ind  past_num_of_claims  \\\n",
       "0               1                   1                   1                   2   \n",
       "1               1                   1                   1                   0   \n",
       "2               1                   0                   1                   1   \n",
       "3               1                   0                   0                   1   \n",
       "4               1                   1                   0                   0   \n",
       "\n",
       "   witness_present_ind  liab_prct  policy_report_filed_ind  fraud  age  \\\n",
       "0                    0          2                        0      1    0   \n",
       "1                    0          2                        0      1    1   \n",
       "2                    1          3                        1      0    2   \n",
       "3                    0          0                        1      0    2   \n",
       "4                    0          0                        0      0    1   \n",
       "\n",
       "   safety_grade  ...  weekday  accident_site_Highway  accident_site_Local  \\\n",
       "0             4  ...        0                      0                    1   \n",
       "1             1  ...        1                      1                    0   \n",
       "2             1  ...        1                      0                    1   \n",
       "3             2  ...        0                      0                    1   \n",
       "4             1  ...        1                      0                    0   \n",
       "\n",
       "   accident_site_Parking Lot  channel_Broker  channel_Online  channel_Phone  \\\n",
       "0                          0               0               1              0   \n",
       "1                          0               0               0              1   \n",
       "2                          0               1               0              0   \n",
       "3                          0               0               0              1   \n",
       "4                          1               1               0              0   \n",
       "\n",
       "   claim_est_payout_category  age_of_vehicle_category  vehicle_price_category  \n",
       "0                          4                        0                       1  \n",
       "1                          4                        2                       0  \n",
       "2                          4                        2                       2  \n",
       "3                          3                        2                       1  \n",
       "4                          4                        0                       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>high_education_ind</th>\n",
       "      <th>address_change_ind</th>\n",
       "      <th>past_num_of_claims</th>\n",
       "      <th>witness_present_ind</th>\n",
       "      <th>liab_prct</th>\n",
       "      <th>policy_report_filed_ind</th>\n",
       "      <th>fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>safety_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday</th>\n",
       "      <th>accident_site_Highway</th>\n",
       "      <th>accident_site_Local</th>\n",
       "      <th>accident_site_Parking Lot</th>\n",
       "      <th>channel_Broker</th>\n",
       "      <th>channel_Online</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>claim_est_payout_category</th>\n",
       "      <th>age_of_vehicle_category</th>\n",
       "      <th>vehicle_price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  high_education_ind  address_change_ind  past_num_of_claims  \\\n",
       "0               1                   1                   1                   0   \n",
       "1               1                   1                   1                   0   \n",
       "2               0                   0                   0                   0   \n",
       "3               0                   1                   1                   0   \n",
       "4               1                   1                   0                   0   \n",
       "\n",
       "   witness_present_ind  liab_prct  policy_report_filed_ind  fraud  age  \\\n",
       "0                    0          3                        0      0    0   \n",
       "1                    0          3                        1      0    1   \n",
       "2                    0          2                        1      0    1   \n",
       "3                    0          3                        0      0    1   \n",
       "4                    0          0                        0      0    1   \n",
       "\n",
       "   safety_grade  ...  weekday  accident_site_Highway  accident_site_Local  \\\n",
       "0             0  ...        1                      0                    0   \n",
       "1             1  ...        1                      0                    1   \n",
       "2             1  ...        1                      0                    1   \n",
       "3             1  ...        0                      0                    1   \n",
       "4             3  ...        1                      0                    1   \n",
       "\n",
       "   accident_site_Parking Lot  channel_Broker  channel_Online  channel_Phone  \\\n",
       "0                          1               0               1              0   \n",
       "1                          0               1               0              0   \n",
       "2                          0               0               1              0   \n",
       "3                          0               1               0              0   \n",
       "4                          0               0               0              1   \n",
       "\n",
       "   claim_est_payout_category  age_of_vehicle_category  vehicle_price_category  \n",
       "0                          4                        1                       1  \n",
       "1                          3                        0                       2  \n",
       "2                          3                        2                       1  \n",
       "3                          1                        1                       2  \n",
       "4                          1                        1                       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Basic Information on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14254, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marital_status               int64\n",
       "high_education_ind           int64\n",
       "address_change_ind           int64\n",
       "past_num_of_claims           int64\n",
       "witness_present_ind          int64\n",
       "liab_prct                    int64\n",
       "policy_report_filed_ind      int64\n",
       "fraud                        int64\n",
       "age                          int64\n",
       "safety_grade                 int64\n",
       "annual_income_category       int64\n",
       "part_of_month                int64\n",
       "weekday                      int64\n",
       "accident_site_Highway        int64\n",
       "accident_site_Local          int64\n",
       "accident_site_Parking Lot    int64\n",
       "channel_Broker               int64\n",
       "channel_Online               int64\n",
       "channel_Phone                int64\n",
       "claim_est_payout_category    int64\n",
       "age_of_vehicle_category      int64\n",
       "vehicle_price_category       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic exploration above, we can see that the preprocessed train dataset has all features of type int64, which are ready for training models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Spliting Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('fraud', axis=1)\n",
    "y_train = train['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('fraud', axis=1)\n",
    "y_test = test['fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking for Imbalance in Target Column of Train Dataset </h2><br>\n",
    "We will plot the distribution of the binary classes 0 and 1 in target column y_train to check if there is imbalance between the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(y_train, palette=[\"green\", \"red\"])\n",
    "plt.xlabel('Fraud')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Fraud in Train Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see clearly that the target is imbalanced with heavy lean towards 0 in the train dataset. To resolve this issue, we will use random oversampling to balance between the two classes in our target for the train dataset before training our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resam, y_resam = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Basic Logistic Regression Model </h2><br>\n",
    "We will firstly train a basic logistic regression model using train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_resam, y_resam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the above model to predict probability of each class in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_lr = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will use the default threshold of 0.5 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_lr = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_lr_def = (y_prob_lr > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will access the performance of this basic logistic regression model through accuracy, precision, recall, f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the basic logistic regression model with default threshold of 0.5: \n",
      "\n",
      "Accuracy: 0.63973\n",
      "Precision: 0.24548\n",
      "Recall: 0.63949\n",
      "F1 Score: 0.35477\n"
     ]
    }
   ],
   "source": [
    "accuracy_lr_def = accuracy_score(y_test, y_pred_lr_def)\n",
    "precision_lr_def = precision_score(y_test, y_pred_lr_def)\n",
    "recall_lr_def = recall_score(y_test, y_pred_lr_def)\n",
    "f1_lr_def = f1_score(y_test, y_pred_lr_def)\n",
    "\n",
    "print(\"Performance of the basic logistic regression model with default threshold of 0.5: \\n\")\n",
    "print(f'Accuracy: {accuracy_lr_def:.5f}')\n",
    "print(f'Precision: {precision_lr_def:.5f}')\n",
    "print(f'Recall: {recall_lr_def:.5f}')\n",
    "print(f'F1 Score: {f1_lr_def:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75      3012\n",
      "           1       0.25      0.64      0.35       552\n",
      "\n",
      "    accuracy                           0.64      3564\n",
      "   macro avg       0.58      0.64      0.55      3564\n",
      "weighted avg       0.80      0.64      0.69      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 353\n",
      "False Positives (FP): 1085\n",
      "True Negatives (TN): 1927\n",
      "False Negatives (FN): 199\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_lr_def))\n",
    "\n",
    "conf_matrix_lr_def = confusion_matrix(y_test, y_pred_lr_def)\n",
    "\n",
    "TP = conf_matrix_lr_def[1, 1]\n",
    "FP = conf_matrix_lr_def[0, 1]\n",
    "TN = conf_matrix_lr_def[0, 0]\n",
    "FN = conf_matrix_lr_def[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP}')\n",
    "print(f'False Positives (FP): {FP}')\n",
    "print(f'True Negatives (TN): {TN}')\n",
    "print(f'False Negatives (FN): {FN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we will use the optimal threshold from the ROC curve for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for the basic logistic regression model: 0.4486923235979855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_prob_lr)\n",
    "\n",
    "# Calculate the Youden index at each threshold setting\n",
    "j_scores_lr = tpr_lr - fpr_lr\n",
    "\n",
    "# Find the threshold setting that maximizes the Youden index\n",
    "optimal_idx_lr = np.argmax(j_scores_lr)\n",
    "optimal_threshold_lr = thresholds_lr[optimal_idx_lr]\n",
    "print(f'Optimal threshold for the basic logistic regression model: {optimal_threshold_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the basic logistic regression model with optimal threshold: \n",
      "\n",
      "Accuracy: 0.57407\n",
      "Precision: 0.23137\n",
      "Recall: 0.75362\n",
      "F1 Score: 0.35404\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_opt = (y_prob_lr > optimal_threshold_lr).astype(int)\n",
    "\n",
    "accuracy_lr_opt = accuracy_score(y_test, y_pred_lr_opt)\n",
    "precision_lr_opt = precision_score(y_test, y_pred_lr_opt)\n",
    "recall_lr_opt = recall_score(y_test, y_pred_lr_opt)\n",
    "f1_lr_opt = f1_score(y_test, y_pred_lr_opt)\n",
    "\n",
    "print(\"Performance of the basic logistic regression model with optimal threshold: \\n\")\n",
    "print(f'Accuracy: {accuracy_lr_opt:.5f}')\n",
    "print(f'Precision: {precision_lr_opt:.5f}')\n",
    "print(f'Recall: {recall_lr_opt:.5f}')\n",
    "print(f'F1 Score: {f1_lr_opt:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.54      0.68      3012\n",
      "           1       0.23      0.75      0.35       552\n",
      "\n",
      "    accuracy                           0.57      3564\n",
      "   macro avg       0.58      0.65      0.52      3564\n",
      "weighted avg       0.82      0.57      0.63      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 416\n",
      "False Positives (FP): 1382\n",
      "True Negatives (TN): 1630\n",
      "False Negatives (FN): 136\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_lr_opt))\n",
    "\n",
    "conf_matrix_lr_opt = confusion_matrix(y_test, y_pred_lr_opt)\n",
    "\n",
    "TP_opt = conf_matrix_lr_opt[1, 1]\n",
    "FP_opt = conf_matrix_lr_opt[0, 1]\n",
    "TN_opt = conf_matrix_lr_opt[0, 0]\n",
    "FN_opt = conf_matrix_lr_opt[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP_opt}')\n",
    "print(f'False Positives (FP): {FP_opt}')\n",
    "print(f'True Negatives (TN): {TN_opt}')\n",
    "print(f'False Negatives (FN): {FN_opt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal threshold has improved the recall of the basic logistic regression model from 0.63949 to 0.75362. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hyperparameter Tuning </h2><br>\n",
    "Next, we will attempt to improve the performance of logistic regression through hyperparameter tuning. We will use <code>GridSearchCV</code> to discover the best parameters that give the best recall over a range of params. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.61821471        nan        nan        nan 0.63053593 0.63536448\n",
      " 0.6380282  0.6380282  0.6380282  0.6380282  0.61821471        nan\n",
      "        nan        nan 0.63053593 0.63536448 0.6380282  0.6380282\n",
      " 0.6380282  0.6380282  0.61821471        nan        nan        nan\n",
      " 0.63053593 0.63536448 0.6380282  0.6380282  0.6380282  0.6380282\n",
      " 0.64077563        nan        nan        nan 0.64219102 0.64260734\n",
      " 0.6427739  0.64260737 0.64260737 0.64260737 0.64077563        nan\n",
      "        nan        nan 0.64219102 0.64260734 0.6427739  0.64260737\n",
      " 0.64260737 0.64260737 0.64077563        nan        nan        nan\n",
      " 0.64219102 0.64260734 0.6427739  0.64260737 0.64260737 0.64260737\n",
      " 0.64194129        nan        nan        nan 0.64177477 0.64202445\n",
      " 0.64219098 0.64219098 0.64219098 0.64219098 0.64194129        nan\n",
      "        nan        nan 0.64210779 0.64202445 0.64202445 0.64219098\n",
      " 0.64219098 0.64219098 0.64194129        nan        nan        nan\n",
      " 0.64210779 0.64202445 0.64202445 0.64219098 0.64219098 0.64219098\n",
      " 0.64219098        nan        nan        nan 0.64210775 0.64235744\n",
      " 0.64210775 0.64235744 0.64235744 0.64235744 0.64219098        nan\n",
      "        nan        nan 0.64210775 0.64235744 0.64210775 0.64235744\n",
      " 0.64235744 0.64235744 0.64219098        nan        nan        nan\n",
      " 0.64210775 0.64235744 0.64210775 0.64235744 0.64235744 0.64235744]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;max_iter&#x27;: [50, 100, 200],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;max_iter&#x27;: [50, 100, 200],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10], 'max_iter': [50, 100, 200],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='recall')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [50, 100, 200],\n",
    "}\n",
    "\n",
    "lr_gs = LogisticRegression(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(lr_gs, param_grid, scoring='recall', cv=5)\n",
    "grid_search.fit(X_resam, y_resam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters from GridSearchCV:\n",
      " {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 50, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters from GridSearchCV:\\n\", grid_search.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> New Logistic Regression Model with Tuned Hyperparameters</h2><br>\n",
    "Lastly, we will train an advanced logistic regression model using the best hyperparameters we obtained from GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=50, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=50, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tuned = LogisticRegression(C=0.1, \n",
    "                              fit_intercept=True,\n",
    "                              max_iter=50,\n",
    "                              multi_class='auto',\n",
    "                              penalty='l2', \n",
    "                              solver='lbfgs',\n",
    "                              random_state=42)\n",
    "lr_tuned.fit(X_resam, y_resam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the above model to predict probability of each class in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_lr_tuned = lr_tuned.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will use the default threshold of 0.5 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_def_tuned = (y_prob_lr_tuned > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will access the performance of this tuned logistic regression model through accuracy, precision, recall, f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the tuned logistic regression model with default threshold of 0.5: \n",
      "\n",
      "Accuracy: 0.63973\n",
      "Precision: 0.24548\n",
      "Recall: 0.63949\n",
      "F1 Score: 0.35477\n"
     ]
    }
   ],
   "source": [
    "accuracy_lr_def_tuned = accuracy_score(y_test, y_pred_lr_def_tuned)\n",
    "precision_lr_def_tuned = precision_score(y_test, y_pred_lr_def_tuned)\n",
    "recall_lr_def_tuned = recall_score(y_test, y_pred_lr_def_tuned)\n",
    "f1_lr_def_tuned = f1_score(y_test, y_pred_lr_def_tuned)\n",
    "\n",
    "print(\"Performance of the tuned logistic regression model with default threshold of 0.5: \\n\")\n",
    "print(f'Accuracy: {accuracy_lr_def_tuned:.5f}')\n",
    "print(f'Precision: {precision_lr_def_tuned:.5f}')\n",
    "print(f'Recall: {recall_lr_def_tuned:.5f}')\n",
    "print(f'F1 Score: {f1_lr_def_tuned:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75      3012\n",
      "           1       0.25      0.64      0.35       552\n",
      "\n",
      "    accuracy                           0.64      3564\n",
      "   macro avg       0.58      0.64      0.55      3564\n",
      "weighted avg       0.80      0.64      0.69      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 353\n",
      "False Positives (FP): 1085\n",
      "True Negatives (TN): 1927\n",
      "False Negatives (FN): 199\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_lr_def_tuned))\n",
    "\n",
    "conf_matrix_lr_def_tuned = confusion_matrix(y_test, y_pred_lr_def_tuned)\n",
    "\n",
    "TP_def_tuned = conf_matrix_lr_def_tuned[1, 1]\n",
    "FP_def_tuned = conf_matrix_lr_def_tuned[0, 1]\n",
    "TN_def_tuned = conf_matrix_lr_def_tuned[0, 0]\n",
    "FN_def_tuned = conf_matrix_lr_def_tuned[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP_def_tuned}')\n",
    "print(f'False Positives (FP): {FP_def_tuned}')\n",
    "print(f'True Negatives (TN): {TN_def_tuned}')\n",
    "print(f'False Negatives (FN): {FN_def_tuned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we will use the optimal threshold from the ROC curve for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for the tuned logistic regression model: 0.43711091806047175\n"
     ]
    }
   ],
   "source": [
    "fpr_lr_tuned, tpr_lr_tuned, thresholds_lr_tuned = roc_curve(y_test, y_prob_lr_tuned)\n",
    "\n",
    "# Calculate the Youden index at each threshold setting\n",
    "j_scores_lr_tuned = tpr_lr_tuned - fpr_lr_tuned\n",
    "\n",
    "# Find the threshold setting that maximizes the Youden index\n",
    "optimal_idx_lr_tuned = np.argmax(j_scores_lr_tuned)\n",
    "optimal_threshold_lr_tuned = thresholds_lr_tuned[optimal_idx_lr_tuned]\n",
    "print(f'Optimal threshold for the tuned logistic regression model: {optimal_threshold_lr_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the tuned logistic regression model with optimal threshold: \n",
      "\n",
      "Accuracy: 0.55976\n",
      "Precision: 0.22822\n",
      "Recall: 0.77355\n",
      "F1 Score: 0.35246\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_opt_tuned = (y_prob_lr_tuned > optimal_threshold_lr_tuned).astype(int)\n",
    "\n",
    "accuracy_lr_opt_tuned = accuracy_score(y_test, y_pred_lr_opt_tuned)\n",
    "precision_lr_opt_tuned = precision_score(y_test, y_pred_lr_opt_tuned)\n",
    "recall_lr_opt_tuned = recall_score(y_test, y_pred_lr_opt_tuned)\n",
    "f1_lr_opt_tuned = f1_score(y_test, y_pred_lr_opt_tuned)\n",
    "\n",
    "print(\"Performance of the tuned logistic regression model with optimal threshold: \\n\")\n",
    "print(f'Accuracy: {accuracy_lr_opt_tuned:.5f}')\n",
    "print(f'Precision: {precision_lr_opt_tuned:.5f}')\n",
    "print(f'Recall: {recall_lr_opt_tuned:.5f}')\n",
    "print(f'F1 Score: {f1_lr_opt_tuned:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.52      0.67      3012\n",
      "           1       0.23      0.77      0.35       552\n",
      "\n",
      "    accuracy                           0.56      3564\n",
      "   macro avg       0.58      0.65      0.51      3564\n",
      "weighted avg       0.82      0.56      0.62      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 427\n",
      "False Positives (FP): 1444\n",
      "True Negatives (TN): 1568\n",
      "False Negatives (FN): 125\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_lr_opt_tuned))\n",
    "\n",
    "conf_matrix_lr_opt_tuned = confusion_matrix(y_test, y_pred_lr_opt_tuned)\n",
    "\n",
    "TP_opt_tuned = conf_matrix_lr_opt_tuned[1, 1]\n",
    "FP_opt_tuned = conf_matrix_lr_opt_tuned[0, 1]\n",
    "TN_opt_tuned = conf_matrix_lr_opt_tuned[0, 0]\n",
    "FN_opt_tuned = conf_matrix_lr_opt_tuned[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP_opt_tuned}')\n",
    "print(f'False Positives (FP): {FP_opt_tuned}')\n",
    "print(f'True Negatives (TN): {TN_opt_tuned}')\n",
    "print(f'False Negatives (FN): {FN_opt_tuned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal threshold has improved the recall of the tuned logistic regression model from 0.63949 to 0.0.76268. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation</h2>\n",
    "<h5>Explanation on choosing recall as the evaluator</h5>\n",
    "\n",
    "Firstly, we will decide on which performance score to use for evaluation by analysing the context of our classification problem.<br><br>\n",
    "\n",
    "Given the context of the dataset, we are dealing with a car insurance fraud classification problem. In this scenario, it is imporant that we catch potential frauds as much as possible, even at the price of wrongly classifying some normal cases to be frauds. <br><be>\n",
    "\n",
    "This is because from the perspective of an insurance company, our goal is to minimise losses due to paying out to fraudulant car accident claims. When a claim is flagged as potentially fraudulant by our classification model, there will be personnels dispatched to further investigate so that innocent cases who were flagged as frauds will still be repaid, and truly fraudulant cases will be caught out to minimise the company's losses. <br><br>\n",
    "\n",
    "Therefore given the above context, we should prioritise <b>recall</b> when evaluating the models. Recall measures the ratio of correctly predicted positives out of all actual positives in a dataset. Recall is particularly important in scenarios where the cost of missing positive instances (false negatives) is high, and capturing all relevant instances of the positive class is a priority. In such cases, a high recall indicates that the model is effective at identifying the majority of positive instances, minimizing the number of cases that go undetected.<br><br>\n",
    "\n",
    "In fraud detection, recall is crucial because missing a fraudulent transaction (false negative) can have severe consequences, including financial losses and damage to the organization's reputation. Therefore, a high recall ensures that the model is sensitive to the presence of fraud and captures as many fraudulent cases as possible.<br><br>\n",
    "\n",
    "Therefore, we will use recall as the main performance score for evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Table of performance scores for both logistic regression models</h5>\n",
    "\n",
    "| Models                                                                | Accuracy | Precision | Recall  | F1 Score |\n",
    "|-----------------------------------------------------------------------|:--------:|:---------:|:-------:|:--------:|\n",
    "| Basic Logistic Regression model with optimal threshold                | 0.57407  | 0.23137   | 0.75362 | 0.35404  | \n",
    "| Hyperparametre-tuned Logistic Regression model with optimal threshold | 0.55976  | 0.22822   | 0.77355 | 0.35246  | <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above performance scores, we can see that hyperparameter tuning led to improvement in recall score of logistic regression model without compromising accuracy, precision and f1 too much. <br><br>\n",
    "The highest recall achieved from logistic regression is 0.76268. We will use this recall score to evaluate logistic regression against other models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
