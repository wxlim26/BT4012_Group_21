{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>high_education_ind</th>\n",
       "      <th>address_change_ind</th>\n",
       "      <th>past_num_of_claims</th>\n",
       "      <th>witness_present_ind</th>\n",
       "      <th>liab_prct</th>\n",
       "      <th>policy_report_filed_ind</th>\n",
       "      <th>fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>safety_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday</th>\n",
       "      <th>accident_site_Highway</th>\n",
       "      <th>accident_site_Local</th>\n",
       "      <th>accident_site_Parking Lot</th>\n",
       "      <th>channel_Broker</th>\n",
       "      <th>channel_Online</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>claim_est_payout_category</th>\n",
       "      <th>age_of_vehicle_category</th>\n",
       "      <th>vehicle_price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  high_education_ind  address_change_ind  past_num_of_claims  \\\n",
       "0               1                   1                   1                   2   \n",
       "1               1                   1                   1                   0   \n",
       "2               1                   0                   1                   1   \n",
       "3               1                   0                   0                   1   \n",
       "4               1                   1                   0                   0   \n",
       "\n",
       "   witness_present_ind  liab_prct  policy_report_filed_ind  fraud  age  \\\n",
       "0                    0          2                        0      1    0   \n",
       "1                    0          2                        0      1    1   \n",
       "2                    1          3                        1      0    2   \n",
       "3                    0          0                        1      0    2   \n",
       "4                    0          0                        0      0    1   \n",
       "\n",
       "   safety_grade  ...  weekday  accident_site_Highway  accident_site_Local  \\\n",
       "0             4  ...        0                      0                    1   \n",
       "1             1  ...        1                      1                    0   \n",
       "2             1  ...        1                      0                    1   \n",
       "3             2  ...        0                      0                    1   \n",
       "4             1  ...        1                      0                    0   \n",
       "\n",
       "   accident_site_Parking Lot  channel_Broker  channel_Online  channel_Phone  \\\n",
       "0                          0               0               1              0   \n",
       "1                          0               0               0              1   \n",
       "2                          0               1               0              0   \n",
       "3                          0               0               0              1   \n",
       "4                          1               1               0              0   \n",
       "\n",
       "   claim_est_payout_category  age_of_vehicle_category  vehicle_price_category  \n",
       "0                          4                        0                       1  \n",
       "1                          4                        2                       0  \n",
       "2                          4                        2                       2  \n",
       "3                          3                        2                       1  \n",
       "4                          4                        0                       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital_status</th>\n",
       "      <th>high_education_ind</th>\n",
       "      <th>address_change_ind</th>\n",
       "      <th>past_num_of_claims</th>\n",
       "      <th>witness_present_ind</th>\n",
       "      <th>liab_prct</th>\n",
       "      <th>policy_report_filed_ind</th>\n",
       "      <th>fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>safety_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday</th>\n",
       "      <th>accident_site_Highway</th>\n",
       "      <th>accident_site_Local</th>\n",
       "      <th>accident_site_Parking Lot</th>\n",
       "      <th>channel_Broker</th>\n",
       "      <th>channel_Online</th>\n",
       "      <th>channel_Phone</th>\n",
       "      <th>claim_est_payout_category</th>\n",
       "      <th>age_of_vehicle_category</th>\n",
       "      <th>vehicle_price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital_status  high_education_ind  address_change_ind  past_num_of_claims  \\\n",
       "0               1                   1                   1                   0   \n",
       "1               1                   1                   1                   0   \n",
       "2               0                   0                   0                   0   \n",
       "3               0                   1                   1                   0   \n",
       "4               1                   1                   0                   0   \n",
       "\n",
       "   witness_present_ind  liab_prct  policy_report_filed_ind  fraud  age  \\\n",
       "0                    0          3                        0      0    0   \n",
       "1                    0          3                        1      0    1   \n",
       "2                    0          2                        1      0    1   \n",
       "3                    0          3                        0      0    1   \n",
       "4                    0          0                        0      0    1   \n",
       "\n",
       "   safety_grade  ...  weekday  accident_site_Highway  accident_site_Local  \\\n",
       "0             0  ...        1                      0                    0   \n",
       "1             1  ...        1                      0                    1   \n",
       "2             1  ...        1                      0                    1   \n",
       "3             1  ...        0                      0                    1   \n",
       "4             3  ...        1                      0                    1   \n",
       "\n",
       "   accident_site_Parking Lot  channel_Broker  channel_Online  channel_Phone  \\\n",
       "0                          1               0               1              0   \n",
       "1                          0               1               0              0   \n",
       "2                          0               0               1              0   \n",
       "3                          0               1               0              0   \n",
       "4                          0               0               0              1   \n",
       "\n",
       "   claim_est_payout_category  age_of_vehicle_category  vehicle_price_category  \n",
       "0                          4                        1                       1  \n",
       "1                          3                        0                       2  \n",
       "2                          3                        2                       1  \n",
       "3                          1                        1                       2  \n",
       "4                          1                        1                       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Basic Information on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14254, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marital_status               int64\n",
       "high_education_ind           int64\n",
       "address_change_ind           int64\n",
       "past_num_of_claims           int64\n",
       "witness_present_ind          int64\n",
       "liab_prct                    int64\n",
       "policy_report_filed_ind      int64\n",
       "fraud                        int64\n",
       "age                          int64\n",
       "safety_grade                 int64\n",
       "annual_income_category       int64\n",
       "part_of_month                int64\n",
       "weekday                      int64\n",
       "accident_site_Highway        int64\n",
       "accident_site_Local          int64\n",
       "accident_site_Parking Lot    int64\n",
       "channel_Broker               int64\n",
       "channel_Online               int64\n",
       "channel_Phone                int64\n",
       "claim_est_payout_category    int64\n",
       "age_of_vehicle_category      int64\n",
       "vehicle_price_category       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic exploration above, we can see that the preprocessed train dataset has all features of type int64, which are ready for training models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Spliting Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('fraud', axis=1)\n",
    "y_train = train['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('fraud', axis=1)\n",
    "y_test = test['fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Standard Scaling </h2><br>\n",
    "We will standardise all features using standard scaling so they are all of the same range. This is to minimise the effect of range on the model's perceived importance of a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking for Imbalance in Target Column of Train Dataset </h2><br>\n",
    "We will plot the distribution of the binary classes 0 and 1 in target column y_train to check if there is imbalance between the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(y_train, palette=[\"green\", \"red\"])\n",
    "plt.xlabel('Fraud')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Fraud in Train Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can see clearly that the target is imbalanced with heavy lean towards 0 in the train dataset. To resolve this issue, we will use random oversampling to balance between the two classes in our target for the train dataset before training our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resam, y_resam = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Basic Neural Network with MLP Classifier </h2><br>\n",
    "We will firstly train a basic neural network with MLP classifier using train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,), \n",
    "                    activation='relu', \n",
    "                    max_iter=1000, \n",
    "                    random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the above model to predict probability of each class in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_mlp = mlp.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will use the default threshold of 0.5 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp_def = (y_prob_mlp > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will access the performance of this basic logistic regression model through accuracy, precision, recall, f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the basic MLP neural network model with default threshold of 0.5: \n",
      "\n",
      "Accuracy: 0.84007\n",
      "Precision: 0.35484\n",
      "Recall: 0.03986\n",
      "F1 Score: 0.07166\n"
     ]
    }
   ],
   "source": [
    "accuracy_mlp_def = accuracy_score(y_test, y_pred_mlp_def)\n",
    "precision_mlp_def = precision_score(y_test, y_pred_mlp_def)\n",
    "recall_mlp_def = recall_score(y_test, y_pred_mlp_def)\n",
    "f1_mlp_def = f1_score(y_test, y_pred_mlp_def)\n",
    "\n",
    "print(\"Performance of the basic MLP neural network model with default threshold of 0.5: \\n\")\n",
    "print(f'Accuracy: {accuracy_mlp_def:.5f}')\n",
    "print(f'Precision: {precision_mlp_def:.5f}')\n",
    "print(f'Recall: {recall_mlp_def:.5f}')\n",
    "print(f'F1 Score: {f1_mlp_def:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91      3012\n",
      "           1       0.35      0.04      0.07       552\n",
      "\n",
      "    accuracy                           0.84      3564\n",
      "   macro avg       0.60      0.51      0.49      3564\n",
      "weighted avg       0.77      0.84      0.78      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 22\n",
      "False Positives (FP): 40\n",
      "True Negatives (TN): 2972\n",
      "False Negatives (FN): 530\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_mlp_def))\n",
    "\n",
    "conf_matrix_mlp_def = confusion_matrix(y_test, y_pred_mlp_def)\n",
    "\n",
    "TP = conf_matrix_mlp_def[1, 1]\n",
    "FP = conf_matrix_mlp_def[0, 1]\n",
    "TN = conf_matrix_mlp_def[0, 0]\n",
    "FN = conf_matrix_mlp_def[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP}')\n",
    "print(f'False Positives (FP): {FP}')\n",
    "print(f'True Negatives (TN): {TN}')\n",
    "print(f'False Negatives (FN): {FN}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we will use the optimal threshold from the ROC curve for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for the basic MLP neural network model: 0.12108389243001082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_mlp, tpr_mlp, thresholds_mlp = roc_curve(y_test, y_prob_mlp)\n",
    "\n",
    "# Calculate the Youden index at each threshold setting\n",
    "j_scores_mlp = tpr_mlp - fpr_mlp\n",
    "\n",
    "# Find the threshold setting that maximizes the Youden index\n",
    "optimal_idx_mlp = np.argmax(j_scores_mlp)\n",
    "optimal_threshold_mlp = thresholds_mlp[optimal_idx_mlp]\n",
    "print(f'Optimal threshold for the basic MLP neural network model: {optimal_threshold_mlp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the basic MLP neural network model with optimal threshold: \n",
      "\n",
      "Accuracy: 0.53732\n",
      "Precision: 0.21683\n",
      "Recall: 0.76087\n",
      "F1 Score: 0.33748\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp_opt = (y_prob_mlp > optimal_threshold_mlp).astype(int)\n",
    "\n",
    "accuracy_mlp_opt = accuracy_score(y_test, y_pred_mlp_opt)\n",
    "precision_mlp_opt = precision_score(y_test, y_pred_mlp_opt)\n",
    "recall_mlp_opt = recall_score(y_test, y_pred_mlp_opt)\n",
    "f1_mlp_opt = f1_score(y_test, y_pred_mlp_opt)\n",
    "\n",
    "print(\"Performance of the basic MLP neural network model with optimal threshold: \\n\")\n",
    "print(f'Accuracy: {accuracy_mlp_opt:.5f}')\n",
    "print(f'Precision: {precision_mlp_opt:.5f}')\n",
    "print(f'Recall: {recall_mlp_opt:.5f}')\n",
    "print(f'F1 Score: {f1_mlp_opt:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.50      0.64      3012\n",
      "           1       0.22      0.76      0.34       552\n",
      "\n",
      "    accuracy                           0.54      3564\n",
      "   macro avg       0.57      0.63      0.49      3564\n",
      "weighted avg       0.81      0.54      0.60      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 420\n",
      "False Positives (FP): 1517\n",
      "True Negatives (TN): 1495\n",
      "False Negatives (FN): 132\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_mlp_opt))\n",
    "\n",
    "conf_matrix_mlp_opt = confusion_matrix(y_test, y_pred_mlp_opt)\n",
    "\n",
    "TP_opt = conf_matrix_mlp_opt[1, 1]\n",
    "FP_opt = conf_matrix_mlp_opt[0, 1]\n",
    "TN_opt = conf_matrix_mlp_opt[0, 0]\n",
    "FN_opt = conf_matrix_mlp_opt[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP_opt}')\n",
    "print(f'False Positives (FP): {FP_opt}')\n",
    "print(f'True Negatives (TN): {TN_opt}')\n",
    "print(f'False Negatives (FN): {FN_opt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal threshold has improved the recall of the basic logistic regression model from 0.03986 to 0.76087."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hyperparameter Tuning </h2><br>\n",
    "Next, we will attempt to improve the performance of logistic regression through hyperparameter tuning. We will use <code>RandomizedSearchCV</code> with K folds validation to discover the best parameters that give the best recall over a range of params. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (199) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (291) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (527) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (101) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yanghaoying/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (501) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "                   estimator=MLPClassifier(random_state=42), n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;,\n",
       "                                                       &#x27;logistic&#x27;],\n",
       "                                        &#x27;alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f9c7493e610&gt;,\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(50,), (100,),\n",
       "                                                               (150,), (200,)],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;invscaling&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;learning_rate_init&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f9c74977220&gt;,\n",
       "                                        &#x27;max_iter&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f9c7493eeb0&gt;,\n",
       "                                        &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "                   estimator=MLPClassifier(random_state=42), n_jobs=-1,\n",
       "                   param_distributions={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;,\n",
       "                                                       &#x27;logistic&#x27;],\n",
       "                                        &#x27;alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f9c7493e610&gt;,\n",
       "                                        &#x27;hidden_layer_sizes&#x27;: [(50,), (100,),\n",
       "                                                               (150,), (200,)],\n",
       "                                        &#x27;learning_rate&#x27;: [&#x27;constant&#x27;,\n",
       "                                                          &#x27;invscaling&#x27;,\n",
       "                                                          &#x27;adaptive&#x27;],\n",
       "                                        &#x27;learning_rate_init&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f9c74977220&gt;,\n",
       "                                        &#x27;max_iter&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f9c7493eeb0&gt;,\n",
       "                                        &#x27;solver&#x27;: [&#x27;sgd&#x27;, &#x27;adam&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;recall&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "                   estimator=MLPClassifier(random_state=42), n_jobs=-1,\n",
       "                   param_distributions={'activation': ['relu', 'tanh',\n",
       "                                                       'logistic'],\n",
       "                                        'alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f9c7493e610>,\n",
       "                                        'hidden_layer_sizes': [(50,), (100,),\n",
       "                                                               (150,), (200,)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'learning_rate_init': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f9c74977220>,\n",
       "                                        'max_iter': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f9c7493eeb0>,\n",
       "                                        'solver': ['sgd', 'adam']},\n",
       "                   random_state=42, scoring='recall')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (200,)],  # Adjust as needed\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': uniform(1e-6, 1e-3),  # Regularization parameter\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': uniform(1e-4, 1e-2),  # Initial learning rate\n",
    "    'max_iter': randint(100, 1000),  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "mlp_rs = MLPClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(mlp_rs, param_distributions=param_dist, n_iter=10, cv=kf, scoring='recall', \n",
    "                                   random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters from RandomizedSearchCV:\n",
      " {'activation': 'relu', 'alpha': 0.0006184815096277166, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.00017066305219717406, 'max_iter': 956, 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters from RandomizedSearchCV:\\n\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> New Logistic Regression Model with Tuned Hyperparameters</h2><br>\n",
    "Lastly, we will train an advanced logistic regression model using the best hyperparameters we obtained from GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.0006184815096277166, batch_size=64,\n",
       "              learning_rate=&#x27;invscaling&#x27;,\n",
       "              learning_rate_init=0.00017066305219717406, max_iter=956,\n",
       "              random_state=42, solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.0006184815096277166, batch_size=64,\n",
       "              learning_rate=&#x27;invscaling&#x27;,\n",
       "              learning_rate_init=0.00017066305219717406, max_iter=956,\n",
       "              random_state=42, solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.0006184815096277166, batch_size=64,\n",
       "              learning_rate='invscaling',\n",
       "              learning_rate_init=0.00017066305219717406, max_iter=956,\n",
       "              random_state=42, solver='sgd')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_tuned = MLPClassifier(max_iter=956,\n",
    "                          learning_rate_init=0.00017066305219717406, \n",
    "                          learning_rate='invscaling', \n",
    "                          hidden_layer_sizes=(100,), batch_size=64, \n",
    "                          alpha=0.0006184815096277166,\n",
    "                          activation='relu',\n",
    "                          solver='sgd',\n",
    "                          random_state=42)\n",
    "mlp_tuned.fit(X_resam, y_resam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the above model to predict probability of each class in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_mlp_tuned = mlp_tuned.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will use the default threshold of 0.5 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp_def_tuned = (y_prob_mlp_tuned > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will access the performance of this tuned MLP neural network model through accuracy, precision, recall, f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the tuned MLP neural network model with default threshold of 0.5: \n",
      "\n",
      "Accuracy: 0.53451\n",
      "Precision: 0.17384\n",
      "Recall: 0.53442\n",
      "F1 Score: 0.26234\n"
     ]
    }
   ],
   "source": [
    "accuracy_mlp_def_tuned = accuracy_score(y_test, y_pred_mlp_def_tuned)\n",
    "precision_mlp_def_tuned = precision_score(y_test, y_pred_mlp_def_tuned)\n",
    "recall_mlp_def_tuned = recall_score(y_test, y_pred_mlp_def_tuned)\n",
    "f1_mlp_def_tuned = f1_score(y_test, y_pred_mlp_def_tuned)\n",
    "\n",
    "print(\"Performance of the tuned MLP neural network model with default threshold of 0.5: \\n\")\n",
    "print(f'Accuracy: {accuracy_mlp_def_tuned:.5f}')\n",
    "print(f'Precision: {precision_mlp_def_tuned:.5f}')\n",
    "print(f'Recall: {recall_mlp_def_tuned:.5f}')\n",
    "print(f'F1 Score: {f1_mlp_def_tuned:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.53      0.66      3012\n",
      "           1       0.17      0.53      0.26       552\n",
      "\n",
      "    accuracy                           0.53      3564\n",
      "   macro avg       0.52      0.53      0.46      3564\n",
      "weighted avg       0.76      0.53      0.60      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 295\n",
      "False Positives (FP): 1402\n",
      "True Negatives (TN): 1610\n",
      "False Negatives (FN): 257\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_mlp_def_tuned))\n",
    "\n",
    "conf_matrix_mlp_def_tuned = confusion_matrix(y_test, y_pred_mlp_def_tuned)\n",
    "\n",
    "TP_def_tuned = conf_matrix_mlp_def_tuned[1, 1]\n",
    "FP_def_tuned = conf_matrix_mlp_def_tuned[0, 1]\n",
    "TN_def_tuned = conf_matrix_mlp_def_tuned[0, 0]\n",
    "FN_def_tuned = conf_matrix_mlp_def_tuned[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP_def_tuned}')\n",
    "print(f'False Positives (FP): {FP_def_tuned}')\n",
    "print(f'True Negatives (TN): {TN_def_tuned}')\n",
    "print(f'False Negatives (FN): {FN_def_tuned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we will use the optimal threshold from the ROC curve for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for the tuned MLP neural network model: 0.3921508848457079\n"
     ]
    }
   ],
   "source": [
    "fpr_mlp_tuned, tpr_mlp_tuned, thresholds_mlp_tuned = roc_curve(y_test, y_prob_mlp_tuned)\n",
    "\n",
    "# Calculate the Youden index at each threshold setting\n",
    "j_scores_mlp_tuned = tpr_mlp_tuned - fpr_mlp_tuned\n",
    "\n",
    "# Find the threshold setting that maximizes the Youden index\n",
    "optimal_idx_mlp_tuned = np.argmax(j_scores_mlp_tuned)\n",
    "optimal_threshold_mlp_tuned = thresholds_mlp_tuned[optimal_idx_mlp_tuned]\n",
    "print(f'Optimal threshold for the tuned MLP neural network model: {optimal_threshold_mlp_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the tuned MLP neural network model with optimal threshold: \n",
      "\n",
      "Accuracy: 0.31762\n",
      "Precision: 0.17316\n",
      "Recall: 0.90217\n",
      "F1 Score: 0.29055\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp_opt_tuned = (y_prob_mlp_tuned > optimal_threshold_mlp_tuned).astype(int)\n",
    "\n",
    "accuracy_mlp_opt_tuned = accuracy_score(y_test, y_pred_mlp_opt_tuned)\n",
    "precision_mlp_opt_tuned = precision_score(y_test, y_pred_mlp_opt_tuned)\n",
    "recall_mlp_opt_tuned = recall_score(y_test, y_pred_mlp_opt_tuned)\n",
    "f1_mlp_opt_tuned = f1_score(y_test, y_pred_mlp_opt_tuned)\n",
    "\n",
    "print(\"Performance of the tuned MLP neural network model with optimal threshold: \\n\")\n",
    "print(f'Accuracy: {accuracy_mlp_opt_tuned:.5f}')\n",
    "print(f'Precision: {precision_mlp_opt_tuned:.5f}')\n",
    "print(f'Recall: {recall_mlp_opt_tuned:.5f}')\n",
    "print(f'F1 Score: {f1_mlp_opt_tuned:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also take a look at the classification report and confusion matrix for this prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.21      0.34      3012\n",
      "           1       0.17      0.90      0.29       552\n",
      "\n",
      "    accuracy                           0.32      3564\n",
      "   macro avg       0.55      0.56      0.32      3564\n",
      "weighted avg       0.81      0.32      0.33      3564\n",
      "\n",
      "Confusion matrix:\n",
      "True Positives (TP): 498\n",
      "False Positives (FP): 2378\n",
      "True Negatives (TN): 634\n",
      "False Negatives (FN): 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_mlp_opt_tuned))\n",
    "\n",
    "conf_matrix_mlp_opt_tuned = confusion_matrix(y_test, y_pred_mlp_opt_tuned)\n",
    "\n",
    "TP_opt_tuned = conf_matrix_mlp_opt_tuned[1, 1]\n",
    "FP_opt_tuned = conf_matrix_mlp_opt_tuned[0, 1]\n",
    "TN_opt_tuned = conf_matrix_mlp_opt_tuned[0, 0]\n",
    "FN_opt_tuned = conf_matrix_mlp_opt_tuned[1, 0]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(f'True Positives (TP): {TP_opt_tuned}')\n",
    "print(f'False Positives (FP): {FP_opt_tuned}')\n",
    "print(f'True Negatives (TN): {TN_opt_tuned}')\n",
    "print(f'False Negatives (FN): {FN_opt_tuned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal threshold has improved the recall of the tuned logistic regression model from 0.63949 to 0.0.76268. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Table of performance scores for both logistic regression models</h5>\n",
    "\n",
    "| Models                                                | Accuracy | Precision | Recall  | F1 Score |\n",
    "|-------------------------------------------------------|:--------:|:---------:|:-------:|:--------:|\n",
    "| Basic MLP model with optimal threshold                | 0.53732  | 0.21683   | 0.76087 | 0.33748  | \n",
    "| Hyperparametre-tuned MLP model with optimal threshold | 0.31762  | 0.17316   | 0.90217 | 0.29055  | <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above performance scores, we can see that hyperparameter tuning led to improvement in recall score of MLP model without compromising accuracy, precision and f1 too much. <br><br>\n",
    "The highest recall achieved from MLP is 0.90217. We will use this recall score to evaluate neural networks against other models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
